{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "ytgqdl2fhq3nkli67idv",
   "authorId": "1862636791025",
   "authorName": "PBOAL2",
   "authorEmail": "pboal@wustl.edu",
   "sessionId": "56b8a580-f927-42f7-b74e-eba07d26e07f",
   "lastEditTime": 1759845844670
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "id": "d08cb42f-ca78-4dcb-84b0-ee81bb677e10",
   "metadata": {
    "language": "python",
    "name": "imports",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# Make sure you add scikit-learn, statsmodels, and matplotlib to the project\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport altair as alt\nimport streamlit as st\n\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\n\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n\n# Display settings\npd.set_option(\"display.max_columns\", 100)\npd.set_option(\"display.width\", 120)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c695373e-ac74-4b62-a1f1-08206cbd5c81",
   "metadata": {
    "name": "intro",
    "collapsed": false
   },
   "source": "# Lab 6: Agricultural Productivity\n\nIn this lab, we’ll be focused on feature engineering: dealing with categorical variables, missing values, and messy data. \nWe’ve been working with Bayer Crop Science to understand agricultural productivity (aka crop yield) in various test fields. Unfortunately, the data was collected by high school students and isn’t the best in terms of quality and consistency. Let’s take a look and see what we can to clean up what we’ve got and still get some useful results from a multiple regression model.\nOur data set is in the CSV file agri_productivity.csv.\n\nWe're giong to do the following activities:\n1. Exploratory Data Analysis\n2. Data Cleansing\n3. Address Skew in Continuous Variables\n4. Handle Missing Data\n5. Dummy Coding\n6. Build and Compare Models\n7. Interpret Coefficients"
  },
  {
   "cell_type": "markdown",
   "id": "7a080677-2177-49c4-b21b-3b62296584c0",
   "metadata": {
    "name": "_1_explore",
    "collapsed": false
   },
   "source": "## 1 - Exploratory Data Analysis\n\nTake a look at the data and come with an assessment and a plan for each variable in preparing for a regression model. Show your work and then provide a markdown cell with your final conclusion for each variable."
  },
  {
   "cell_type": "code",
   "id": "d64d75f3-2981-4914-a6db-7423760b94b9",
   "metadata": {
    "language": "python",
    "name": "read_csv",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "ag = pd.read_csv('agri_productivity.csv')\nag.head()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0e77b700-d3d3-4e37-9531-56ace8d69aba",
   "metadata": {
    "language": "python",
    "name": "describe"
   },
   "outputs": [],
   "source": "ag.describe()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d83711c2-e6bf-4677-9d49-f49a3c21347b",
   "metadata": {
    "language": "python",
    "name": "count_nulls",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "ag.isna().sum()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "89282645-7889-4b6a-9ad6-09c041a85594",
   "metadata": {
    "name": "comments_null",
    "collapsed": false
   },
   "source": "### Null Handling\n\nLooks like we're going to need to either throw out **Irrigation Method** all together or find a way to fill that. We'll look at the values in a minute and decide what to do.\n\nWith **Pesticide Use**, we may be able to fill that or just ignore those records. It's only 15 out of 300."
  },
  {
   "cell_type": "code",
   "id": "b0a1f526-7266-46b3-8af2-2e0668fe6abb",
   "metadata": {
    "language": "python",
    "name": "cat_distrib"
   },
   "outputs": [],
   "source": "# Simple function to plot a categorical histogram\ndef hist(df, cat, t):\n    chart = alt.Chart(ag).mark_bar().encode(\n        x = alt.X(cat, type=t, bin=(t=='quantitative')),\n        y = \"count()\"\n    )\n\n    return chart\n\n# Create charts for each categorical variable and display in a row\ncharts = [hist(ag, c, 'nominal') for c in ['Crop_Type','Irrigation_Method','Soil_Quality']]\nst.altair_chart(alt.hconcat(*charts))",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5133c463-6afd-4bea-ae2b-21f93760eb09",
   "metadata": {
    "name": "comments_categoricals",
    "collapsed": false
   },
   "source": "### Categorical Variables\n\n**Crop Type** (nominal) and **Soil Quality** (ordinal) look fine to use.\n\n**Irrigation Method** has LOTS of missing data and some other messy inputs. Makes you wonder how they captured this information.  Probably, we're going to need to make \"null\" into a kind of \"unknown\" value. Or maybe we just ignore that column entirely."
  },
  {
   "cell_type": "markdown",
   "id": "501c08c4-30f2-4b28-9497-ff3bea66dc4b",
   "metadata": {
    "name": "_2_data_cleansing",
    "collapsed": false
   },
   "source": "## 2 - Data Cleansing\n\nLook at any categorical variables and clean up or standardize the values you find.\n\nWe've decided we need to do the following data cleansing steps:\n1. Standardize **Irrigation Method** format and replace NA with \"Unknown\"\n\n_Other activities like dummy coding and transformation will happen in later steps_"
  },
  {
   "cell_type": "code",
   "id": "d0231aa2-251f-48a4-b9a6-36219409009c",
   "metadata": {
    "language": "python",
    "name": "normalize_irrigation"
   },
   "outputs": [],
   "source": "# Strip Spaces\n# Title Case (initial caps)\n\nag['clean_Irrigation_Method'] = ag['Irrigation_Method'].str.strip().str.title()\n\nst.altair_chart(hist(ag, 'clean_Irrigation_Method', t='nominal'))",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "94af9d8f-497e-4d12-9c9f-fafcead93685",
   "metadata": {
    "name": "_3_address_skew",
    "collapsed": false
   },
   "source": "## 3 - Address Skew in Continuous Variables\n\nCreate histograms for any continuous variables and use a transformation to address any skew they may have."
  },
  {
   "cell_type": "code",
   "id": "d16dfc43-43ec-4c24-945a-c69dcc25190d",
   "metadata": {
    "language": "python",
    "name": "cont_distrib",
    "codeCollapsed": false,
    "collapsed": false
   },
   "outputs": [],
   "source": "charts = [hist(ag, c, 'quantitative') for c in [\n    'Fertilizer_Amount_kg_per_acre',\n    'Rainfall_inches',\n    'Pesticide_Use_liters_per_acre',\n    'Yield_tons_per_acre']]\n\nst.altair_chart(alt.vconcat(*charts))",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d390cc85-5a50-451d-b019-2b227ace68b9",
   "metadata": {
    "name": "comment_continuous",
    "collapsed": false
   },
   "source": "### Continuous Variables\n\nLooks like **Yield** and **Pesticide Use** are both normally distributed.\n\n**Fertilizer** and **Rainfall** are right-skewed, however. We'll need to transform those with either a log or sqrt transformation. I'm thinking **log** for **Fertilizer** and **sqrt** for **Rainfall**"
  },
  {
   "cell_type": "code",
   "id": "f2d71250-ebf0-4cce-83da-68141a6127db",
   "metadata": {
    "language": "python",
    "name": "continuous_transform"
   },
   "outputs": [],
   "source": "# Log transform (using log1p incase there are 0s) for Fertilizer\nag['log_Fertilizer_Amount_kg_per_acre'] = np.log1p(ag['Fertilizer_Amount_kg_per_acre'])\n\n# Sqrt transform for Rainfall\nag['sqrt_Rainfall_inches'] = np.sqrt(ag['Rainfall_inches'])\n\n# Show plots on the transformed variables\ncharts = [hist(ag, c, 'quantitative') for c in [\n    'log_Fertilizer_Amount_kg_per_acre',\n    'sqrt_Rainfall_inches']]\n\nst.altair_chart(alt.hconcat(*charts))",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "17b31e50-54e3-49b5-b27b-a31fad4e7a60",
   "metadata": {
    "name": "comment_transform",
    "collapsed": false
   },
   "source": "These definitely look more normally distributed."
  },
  {
   "cell_type": "markdown",
   "id": "afbdf092-9c1c-4170-86fd-b1d555258054",
   "metadata": {
    "name": "_4_missing_data",
    "collapsed": false
   },
   "source": "## 4 - Handle Missing Data\n\nCreate a baseline dataframe by simply dropping any records with missing values. How many records do you have?\nEvaluate each of the fields with missing data and determine how to best fill those missing values. Mode, Mean, MICE, Imputation based on other fields\n\n\nWe have missing values:\n1. **Irrigation Method** - Let's just replace these with 'Unknown' and try that approach versus throwing out the variable\n2. **Pesticide Use** - Let's use mean and iterative imputer on pesticide and compare at the end"
  },
  {
   "cell_type": "code",
   "id": "685758d9-dadb-41db-8149-df5597c9d8a5",
   "metadata": {
    "language": "python",
    "name": "fill_irrigation"
   },
   "outputs": [],
   "source": "ag['imp_Irrigation_Method'] = ag['clean_Irrigation_Method'].fillna('Unknown')\n\nst.altair_chart(hist(ag, 'imp_Irrigation_Method', t='nominal'))",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3352893f-1f88-421c-b092-d08c5a8aea1b",
   "metadata": {
    "language": "python",
    "name": "mean_pesticide"
   },
   "outputs": [],
   "source": "ag['mean_Pesticide_Use_liters_per_acre'] = ag['Pesticide_Use_liters_per_acre'].fillna(ag['Pesticide_Use_liters_per_acre'].mean())",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "504ea214-506b-48d7-bf21-524d9e5b304b",
   "metadata": {
    "language": "python",
    "name": "impute_pesticide",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# The iterative imputer uses correlation with other columns to try to fill missing values least awkwardly\n# https://scikit-learn.org/stable/modules/generated/sklearn.impute.IterativeImputer.html\n\ncols = [\"Pesticide_Use_liters_per_acre\", \"Fertilizer_Amount_kg_per_acre\", \"Rainfall_inches\", \"Yield_tons_per_acre\"]\n\n# random_state=42 to have a repeatability, any integer is fine\n# sample_posterior=True because we're doing multiple imputations\n# max_iter=100 because that's what I wanted... in reality, some trial and error is necessary\nimputer = IterativeImputer(random_state=42, sample_posterior=True, max_iter=100)\n\n# Create a copy of the columns we need because the imputer fills in place\nimp_ag = ag[cols].copy()\nimp_ag[cols] = imputer.fit_transform(imp_ag[cols])\n\n\n# Copy the imputed pesticide use back to our original df\nag['imp_Pesticide_Use_liters_per_acre'] = imp_ag['Pesticide_Use_liters_per_acre']\n\n\n# Show some examples where we imputed values\nag.loc[\n    ag['Pesticide_Use_liters_per_acre'].isnull(),\n    ['imp_Pesticide_Use_liters_per_acre','Pesticide_Use_liters_per_acre']].head()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "35bb7a0b-2907-4d8a-9fb7-89dea064582e",
   "metadata": {
    "name": "_5_dummy_coding",
    "collapsed": false
   },
   "source": "## 5 - Dummy Coding\n\nUse dummy encoding with each categorical variable. Make sure you can explain what to the coefficients of a dummy-coded variable means before going any further.\n\n* Dummy code **Crop_Type** -- drop \"Corn\" as our reference since it was the mode\n* Dummy code **Irrigation_Method** -- drop \"None\" as our reference\n* Ordinal code **Soil Quality** as 1,2,3"
  },
  {
   "cell_type": "code",
   "id": "4e1cad12-12f2-45b7-b671-106ac11f7ce8",
   "metadata": {
    "language": "python",
    "name": "dummy_crop_type"
   },
   "outputs": [],
   "source": "# prefix give us the word \"Crop\" in front of each dummy column name\n# drop \"Corn\"\ncrop_dummies = pd.get_dummies(ag['Crop_Type'], prefix='Crop').drop(columns=['Crop_Corn'])\ncrop_dummies.head()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d312d6ef-5912-4821-a489-a1e4a9e725d4",
   "metadata": {
    "language": "python",
    "name": "dummy_irrigation_method"
   },
   "outputs": [],
   "source": "# prefix with \"IM\"\n# drop \"None\"\nim_dummies = pd.get_dummies(ag['imp_Irrigation_Method'], prefix='IM').drop(columns=['IM_None'])\nim_dummies.head()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "289ae912-5d07-4c33-ae05-b43820c97441",
   "metadata": {
    "language": "python",
    "name": "ordinal_soil_quality"
   },
   "outputs": [],
   "source": "ag['ord_Soil_Quality'] = ag['Soil_Quality'].map({\n    'Poor': 1,\n    'Fair': 2,\n    'Good': 3\n})\n\nhist(ag, 'ord_Soil_Quality', 'nominal')",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "86a687cb-dabb-411a-b4bf-652c269fef2f",
   "metadata": {
    "language": "python",
    "name": "package_df"
   },
   "outputs": [],
   "source": "# Package all the dummies together into one final data frame\nag_model = pd.concat([ag, crop_dummies, im_dummies], axis=1)\nag_model.head(25)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "acfdf072-5e0c-4354-8141-0ececa9eaff6",
   "metadata": {
    "name": "_6_build_models",
    "collapsed": false
   },
   "source": "## 6 - Build and Compare Models\n\nBuild models using the baseline data and using imputed and transformed variables. Compare the models.\n\n1. Model with clean columns but no transformations\n2. Model with basic imputation and transformations\n3. Model with iterative imputation and transformations"
  },
  {
   "cell_type": "code",
   "id": "d3d687d4-083e-43f4-b096-a35fba0a4ee7",
   "metadata": {
    "language": "python",
    "name": "model_1_basic"
   },
   "outputs": [],
   "source": "formula_1 = \"\"\"\nYield_tons_per_acre ~ \n    ord_Soil_Quality + \n    Fertilizer_Amount_kg_per_acre + \n    Rainfall_inches + \n    Pesticide_Use_liters_per_acre + \n    Crop_Soybeans + Crop_Wheat + \n    IM_Drip + IM_Sprinkler + IM_Unknown\"\"\"\n\nmodel_1 = smf.ols(formula=formula_1, data=ag_model).fit()\nprint(model_1.summary())",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d06814e9-738f-4327-b2fc-b9740b97f70b",
   "metadata": {
    "language": "python",
    "name": "model_2_cleansed",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "formula_2 = \"\"\"\nYield_tons_per_acre ~ \n    ord_Soil_Quality + \n    log_Fertilizer_Amount_kg_per_acre + \n    sqrt_Rainfall_inches + \n    mean_Pesticide_Use_liters_per_acre + \n    Crop_Soybeans + Crop_Wheat + \n    IM_Drip + IM_Sprinkler + IM_Unknown\"\"\"\n\nmodel_2 = smf.ols(formula=formula_2, data=ag_model).fit()\nprint(model_2.summary())",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "94aabab8-7e72-42f4-93bb-9fdc6353567c",
   "metadata": {
    "language": "python",
    "name": "model_3_imputed"
   },
   "outputs": [],
   "source": "formula_3 = \"\"\"\nYield_tons_per_acre ~ \n    ord_Soil_Quality + \n    log_Fertilizer_Amount_kg_per_acre + \n    sqrt_Rainfall_inches + \n    imp_Pesticide_Use_liters_per_acre + \n    Crop_Soybeans + Crop_Wheat + \n    IM_Drip + IM_Sprinkler + IM_Unknown\"\"\"\n\nmodel_3 = smf.ols(formula=formula_3, data=ag_model).fit()\nprint(model_3.summary())",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8f8ab32f-2691-43b3-b627-24b34420ce62",
   "metadata": {
    "name": "interpret_models",
    "collapsed": false
   },
   "source": "### Model Interpretation\n\n```\nModel                                    Adj R2\nModel 1 (Cleansed, No Transformations)    0.337\nModel 2 (Simple Cleans, Transformed)      0.353\nModel 3 (Imputations, Transformed)        0.354\n```\n\nWe see improvement in the R2 for each iteration. \n\nWe've got strong p-values for Soil Qualtiy, Fertilizer Amount, and Rainfall in all models. So, it's good to have consistency.\n\n"
  },
  {
   "cell_type": "markdown",
   "id": "7012a4c9-0bd1-413f-8489-8bf7bf274529",
   "metadata": {
    "name": "_7_interpret",
    "collapsed": false
   },
   "source": "## 7 - Interpret Coefficients\n\nExplain what the various coefficients mean. Remember to adjust your interpretation based on any transformations."
  },
  {
   "cell_type": "code",
   "id": "45227a0f-7c29-4a53-ae1b-2a13561fe331",
   "metadata": {
    "language": "python",
    "name": "compare_coefs"
   },
   "outputs": [],
   "source": "coefs = pd.DataFrame({\n    'Model 1 (clean, no transform)': model_1.params,\n    'Model 2 (mean, transformed)': model_2.params,\n    'Model 3 (impute, transformed)': model_3.params\n})\n\ncoefs",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cb441acb-f7b6-45f5-8d7a-dc56c5c5e7dd",
   "metadata": {
    "name": "interpret_coefs"
   },
   "source": "While only Soil Quality, Fertilizer Amount, and Rainfall have significance, we can provide the following interpretation of the coefficients. Yield in tons per acre increases by 1 ton based on the following changes based on our best model (model 3):\n\n* If the crop is Soybeans rather than Corn: -0.1404\n* If the crop is What rather than Corn: -0.1294\n* ... That is, **Corn may provide the highest yield of all the crop types**\n* If Drip irrigation is definitely being used rather than nothing: 0.2333\n* If Sprinkler irrigation is definitely being used rather than nothing: 0.0668\n* If irrigation is Unknown: -0.2023\n* ... That is, **Drip irrigation provides the highest boost to crop yeild**\n* **Pesticide use delivers 0.0673 to 0.0754 more yield for each additional liter of pesticide per acre**\n* **Each step up in Soil Quality delivers a 0.2553 to 0.2639 increase in tons yeild per acre**\n* An increase of **1 unit in the square root of inches of Rainfall increases yield by 0.1486 tons per acre**\n\n**If we can only choose one thing to do with our crops, choosing Drip irrigation has the greatest impact on yeild!**"
  }
 ]
}