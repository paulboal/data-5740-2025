{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "igfe544gm3owyvf4q2zg",
   "authorId": "1862636791025",
   "authorName": "PBOAL2",
   "authorEmail": "pboal@wustl.edu",
   "sessionId": "5fac9c0b-81c0-4b28-a3c9-70c6489a8828",
   "lastEditTime": 1758683362008
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "name": "intro",
    "collapsed": false
   },
   "source": "# Exercise 04\n\n## Section 2: Predicting customer spending\n\nWeâ€™ll be using the customers.csv data set for this exercise. The data set covers the demographic characteristics of some customers and the amount they spent over the past year at an online retailer. For this exercise it is recommended to use the sklearn packages for linear regression, ridge, and lasso. Sklearn documentation linked below.\n\nLinear regression: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n\nRidge: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html \n\nLasso: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html\n\nIn order to interact the categorical variables you will need to dummy code them and manually multiply, an example is given below. \n\n```python\ncustomerDf = pd.get_dummies(data=customerDf, columns=['sex', 'race'], prefix=['sex','race'])\ncustomerDf[\"Hispanic_Male\"] = np.multiply(customerDf[\"race_hispanic\"],customerDf[\"sex_male\"])\n```"
  },
  {
   "cell_type": "code",
   "id": "c695373e-ac74-4b62-a1f1-08206cbd5c81",
   "metadata": {
    "language": "python",
    "name": "imports"
   },
   "source": "import pandas as pd\nimport numpy as np\nimport streamlit as st\nimport statsmodels.api as sm\nimport altair as alt\nfrom sklearn.linear_model import Ridge, Lasso, LinearRegression",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "e365c194-6f88-4e5f-a320-e441aeecdd75",
   "metadata": {
    "language": "python",
    "name": "data",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "customer = pd.read_csv('customers.csv')",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6b9a877f-5e6b-4c53-b381-38e3f46488e3",
   "metadata": {
    "name": "_01_linear_regression",
    "collapsed": false
   },
   "source": "### 1. Build Linear Regression Model\n\nBuild a linear regression with all the dependent variables and two way interactions between sex and race, consider the other category for race and sex to be the reference category and treat it appropriately."
  },
  {
   "cell_type": "code",
   "id": "b392495d-d969-4cb9-bd4a-3c25da68b9d0",
   "metadata": {
    "language": "python",
    "name": "dummy_code"
   },
   "outputs": [],
   "source": "# Get our binary dummy columns based on combinations of sex and race values\n# Note that you have to tell get_dummies() to create ints instead of bools\n# OLS doesn't like bool columns\ncustomer = pd.get_dummies(data=customer, columns=['sex', 'race'], prefix=['sex','race'], dtype=int)\n\n# Create our combination columns by multiplying the individual binary columns\n# We can leave out the \"other\" values since they're the default condition\n\ncustomer[\"hispanic_male\"] = np.multiply(customer[\"race_hispanic\"],customer[\"sex_male\"])\ncustomer[\"hispanic_female\"] = np.multiply(customer[\"race_hispanic\"],customer[\"sex_female\"])\n#customer[\"hispanic_other\"] = np.multiply(customer[\"race_hispanic\"],customer[\"sex_other\"])\n\ncustomer[\"asian_male\"] = np.multiply(customer[\"race_asian\"],customer[\"sex_male\"])\ncustomer[\"asian_female\"] = np.multiply(customer[\"race_asian\"],customer[\"sex_female\"])\n#customer[\"asian_other\"] = np.multiply(customer[\"race_asian\"],customer[\"sex_other\"])\n\ncustomer[\"black_male\"] = np.multiply(customer[\"race_black\"],customer[\"sex_male\"])\ncustomer[\"black_female\"] = np.multiply(customer[\"race_black\"],customer[\"sex_female\"])\n#customer[\"black_other\"] = np.multiply(customer[\"race_black\"],customer[\"sex_other\"])\n\ncustomer[\"white_male\"] = np.multiply(customer[\"race_white\"],customer[\"sex_male\"])\ncustomer[\"white_female\"] = np.multiply(customer[\"race_white\"],customer[\"sex_female\"])\n#customer[\"white_other\"] = np.multiply(customer[\"race_white\"],customer[\"sex_other\"])\n\n#customer[\"other_male\"] = np.multiply(customer[\"race_other\"],customer[\"sex_male\"])\n#customer[\"other_female\"] = np.multiply(customer[\"race_other\"],customer[\"sex_female\"])\n#customer[\"other_other\"] = np.multiply(customer[\"race_other\"],customer[\"sex_other\"])\n\ncustomer.drop(columns=['sex_other', 'race_other'], inplace=True)\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bb8968b8-826c-4d9c-903e-297cace94fa4",
   "metadata": {
    "language": "python",
    "name": "transform_income",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# Income is often very skewed and needs to be log transformed\ncustomer[\"log_income\"] = np.log(customer[\"income\"])",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "22dd7a6d-5e5a-438c-be26-e3d7b773393b",
   "metadata": {
    "language": "python",
    "name": "linear_regression",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# Use all the input except \"spend\" and untransformed \"income\"\nxcols = list(customer.columns.values)\nxcols.remove('spend')\nxcols.remove('income')\n\nX = customer[xcols]\nY = customer['spend']\nX = sm.add_constant(X)\n\nmodel = sm.OLS(np.asarray(Y),np.asarray(X))\nresults = model.fit()\nresults.summary()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b2e714a3-c898-4b3d-a6f0-ec46d72104af",
   "metadata": {
    "name": "_02_03_ridge_lasso_models",
    "collapsed": false
   },
   "source": "### 2. Build a ridge model with different alphas\n\nBuild ridge models with various values for alpha. Create a chart showing how the coefficients change with alpha values\n\nRidge Regression (L2) - https://www.youtube.com/watch?v=Q81RR3yKn30&t=85s\n\nLasso Regression "
  },
  {
   "cell_type": "code",
   "id": "aab44a6b-9eb7-4be8-8cab-2ee223092807",
   "metadata": {
    "language": "python",
    "name": "train_ridge_lasso"
   },
   "outputs": [],
   "source": "import warnings\nwarnings.filterwarnings(\"ignore\")\n\n\n# Start without the intercept term.\n# Not needed for Ridge or Lasso\nX = customer[xcols]\n\n# linear = LinearRegression(fit_intercept=False).fit(X,Y)\n\n# Let's use 100 different values of alpha (aka: lambda) between 10^-5 and 10^2\nn_alphas = 100\nalphas = np.logspace(-5, 2, n_alphas)\n\n# Keep track of the resulting coefficients\nridge_coefs = []\nlasso_coefs = []\n\n# Then fit ridge and lasso models for each value of alpha\nfor a in alphas:\n    # print(f'Fitting alpha = {a}')\n    ridge = Ridge(alpha=a, fit_intercept=False)\n    lasso = Lasso(alpha=a, fit_intercept=False)\n    ridge.fit(X,Y)\n    lasso.fit(X,Y)\n    ridge_coefs.append(ridge.coef_)\n    lasso_coefs.append(lasso.coef_)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "01323e4c-e425-4a26-aa01-ad9a5a967794",
   "metadata": {
    "language": "python",
    "name": "ridge_plot",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# Put together a df with alphas and coefficients\nridges = pd.DataFrame()\nridges['alpha'] = alphas\nridges['coefs'] = ridge_coefs\n\n# Give the coefficients a name\nridges['labels'] = [xcols] * len(ridge_coefs)\n\n# Explode them into multiple rows so we can plot them as separate series\nridges = ridges.explode(['coefs','labels'])\n\n# Line Chart\nc = alt.Chart(ridges).mark_line().encode(\n    alt.X('alpha', title='L2 Penalty', scale=alt.Scale(type=\"log\", reverse=True)),\n    alt.Y('coefs', title='Coefficients'),\n    color='labels'\n).properties(\n    title='Ridge Coefficients as a function of Regularization',\n    height=500\n)\n\nst.altair_chart(c, use_container_width=True)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "20b7acb2-e610-4a5c-be95-b899eb3f26b5",
   "metadata": {
    "language": "python",
    "name": "lasso_plot",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# Put together a df with alphas and coefficients\nlasso = pd.DataFrame()\nlasso['alpha'] = alphas\nlasso['coefs'] = lasso_coefs\n\n# Give the coefficients a name\nlasso['labels'] = [xcols] * len(lasso_coefs)\n\n# Explode them into multiple rows so we can plot them as separate series\nlasso = lasso.explode(['coefs','labels'])\n\n# Line Chart\nc = alt.Chart(lasso).mark_line().encode(\n    alt.X('alpha', title='L2 Penalty', scale=alt.Scale(type=\"log\", reverse=True)),\n    alt.Y('coefs', title='Coefficients'),\n    color='labels'\n).properties(\n    title='Lasso Coefficients as a function of Regularization',\n    height=500\n)\n\nst.altair_chart(c, use_container_width=True)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6151b2c9-3922-4b02-a430-4fd6d9da9356",
   "metadata": {
    "name": "_04_compare",
    "collapsed": false
   },
   "source": "### 4. Compare the coefficients from linear regression, ridge, and lasso (select an alpha value using your chart)\n\n* Regression\n* Ridge with alpha=0.01\n* Lasso with alpha=0.0001"
  },
  {
   "cell_type": "code",
   "id": "dc3be8e5-45d5-440e-9b85-f4b0d6b5c007",
   "metadata": {
    "language": "python",
    "name": "compare"
   },
   "outputs": [],
   "source": "# Choosing 0.01 for Ridge because it seems that we've resolved the coefficients at that level\nridge = Ridge(alpha=0.01, fit_intercept=False)\nridge.fit(X,Y)\n\n# Lasso at 0.001 for the same reason\nlasso = Lasso(alpha=0.0001, fit_intercept=False)\nlasso.fit(X,Y)\n\n# Linear model\nlinear = LinearRegression(fit_intercept=False)\nlinear.fit(X,Y)\n\n\nprint(f'linear regression coefficients {linear.coef_}\\nR2={linear.score(X,Y)}\\n\\n')\nprint(f'ridge regression coefficients {ridge.coef_}\\nR2={ridge.score(X,Y)}\\n\\n')\nprint(f'lasso regression coefficients {lasso.coef_}\\nR2={lasso.score(X,Y)}\\n\\n')\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1379aefe-6816-4095-b7a5-12b760c1def8",
   "metadata": {
    "language": "python",
    "name": "coefficients",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# Package up the coefficients into a table\nout = pd.DataFrame(list(zip(\n    xcols,\n    linear.coef_, \n    ridge.coef_,\n    lasso.coef_)),\n   columns=['variable',\n            f'linear ({linear.score(X,Y):.4f})',\n            f'ridge ({ridge.score(X,Y):.4f})',\n            f'lasso ({lasso.score(X,Y):.4f})'])\nout",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c7f43de5-9738-4581-8807-7c9600b66637",
   "metadata": {
    "language": "python",
    "name": "cell1",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "",
   "execution_count": null
  }
 ]
}