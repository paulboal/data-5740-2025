{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08b43b10",
   "metadata": {},
   "source": [
    "# Generating TruthyNet Social Media Post Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a94b53d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote social_truthy_dataset.csv with 2000 rows.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def generate_truthy_data(n_samples=2000, true_ratio=0.6, label_noise=0.1, random_state=42):\n",
    "    \"\"\"\n",
    "    Generate a synthetic 'truthy vs non-truthy' social media dataset.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_samples : int\n",
    "        Number of rows to generate.\n",
    "    true_ratio : float\n",
    "        Base fraction of rows that are labeled true before noise.\n",
    "    label_noise : float\n",
    "        Probability of flipping each label (to make the task imperfect).\n",
    "    random_state : int\n",
    "        Random seed for reproducibility.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df : pandas.DataFrame\n",
    "        Synthetic dataset with features and label_is_true.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(random_state)\n",
    "\n",
    "    # Start with \"intended\" labels (before noise)\n",
    "    base_labels = rng.binomial(1, true_ratio, size=n_samples)\n",
    "\n",
    "    source_credibility = np.empty(n_samples)\n",
    "    has_citation = np.empty(n_samples, dtype=int)\n",
    "    emotional_tone = np.empty(n_samples)\n",
    "    all_caps_ratio = np.empty(n_samples)\n",
    "    exclamation_count = np.empty(n_samples, dtype=int)\n",
    "    reading_level = np.empty(n_samples)\n",
    "    user_past_accuracy = np.empty(n_samples)\n",
    "\n",
    "    for i, is_true in enumerate(base_labels):\n",
    "        if is_true == 1:\n",
    "            # TRUE POSTS: calm, cited, credible, more accurate users\n",
    "            source_credibility[i] = rng.beta(5, 1.5)          # skew high (0.7–1.0)\n",
    "            has_citation[i] = rng.binomial(1, 0.8)           # usually cited\n",
    "            emotional_tone[i] = rng.beta(2, 5)               # mostly low\n",
    "            all_caps_ratio[i] = rng.beta(1.2, 8)             # close to 0\n",
    "            exclamation_count[i] = min(rng.poisson(0.3), 5)  # mostly 0–1\n",
    "            reading_level[i] = np.clip(rng.normal(8, 1.2), 4, 10)\n",
    "            user_past_accuracy[i] = rng.beta(5, 1.5)         # usually high\n",
    "        else:\n",
    "            # FALSE / MISLEADING POSTS: emotional, shouty, less credible\n",
    "            source_credibility[i] = rng.beta(1.5, 4.5)       # skew low (0–0.5)\n",
    "            has_citation[i] = rng.binomial(1, 0.2)           # usually no citation\n",
    "            emotional_tone[i] = rng.beta(4, 2)               # higher emotion\n",
    "            all_caps_ratio[i] = rng.beta(3, 3)               # wider range\n",
    "            exclamation_count[i] = min(rng.poisson(1.5), 10) # more exclamation marks\n",
    "            reading_level[i] = np.clip(rng.normal(5.5, 1.5), 1, 10)\n",
    "            user_past_accuracy[i] = rng.beta(2, 3.5)         # usually lower\n",
    "\n",
    "    # Add label noise to keep it realistic (model can’t be perfect)\n",
    "    noisy_labels = base_labels.copy()\n",
    "    flip_mask = rng.random(n_samples) < label_noise\n",
    "    noisy_labels[flip_mask] = 1 - noisy_labels[flip_mask]\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"post_id\": np.arange(1, n_samples + 1),\n",
    "        \"source_credibility\": source_credibility,\n",
    "        \"has_citation\": has_citation,\n",
    "        \"emotional_tone\": emotional_tone,\n",
    "        \"all_caps_ratio\": all_caps_ratio,\n",
    "        \"exclamation_count\": exclamation_count,\n",
    "        \"reading_level\": reading_level,\n",
    "        \"user_past_accuracy\": user_past_accuracy,\n",
    "        \"label_is_true\": noisy_labels\n",
    "    })\n",
    "\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82fcc3cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote social_truthy_dataset.csv with 2000 rows.\n"
     ]
    }
   ],
   "source": [
    "df = generate_truthy_data(\n",
    "    n_samples=2000,\n",
    "    true_ratio=0.6,\n",
    "    label_noise=0.1,\n",
    "    random_state=67\n",
    ")\n",
    "df.to_csv(\"social_truthy_dataset.csv\", index=False)\n",
    "print(\"Wrote social_truthy_dataset.csv with\", len(df), \"rows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b657c6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote less_truthy_dataset.csv with 2000 rows.\n"
     ]
    }
   ],
   "source": [
    "df = generate_truthy_data(\n",
    "    n_samples=2000,\n",
    "    true_ratio=0.1,\n",
    "    label_noise=0.2,\n",
    "    random_state=67\n",
    ")\n",
    "df.to_csv(\"less_truthy_dataset.csv\", index=False)\n",
    "print(\"Wrote less_truthy_dataset.csv with\", len(df), \"rows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc85afa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data5740",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
